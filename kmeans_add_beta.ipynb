{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f603c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what happens if loosen control over optimization\n",
    "# introduce beta factors\n",
    "# loosen control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689db92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"3\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "data_path=\"E:\\\\5 Code\\\\2025_cu_qmim\\\\data\" #修改为data存储路径\n",
    "\n",
    "metric_data=os.path.join(data_path,'price_metrics.parquet')\n",
    "std_data=os.path.join(data_path,'factors_std.parquet')\n",
    "px_all = pd.read_parquet(metric_data)\n",
    "factors_std = pd.read_parquet(std_data)\n",
    "\n",
    "# Extract PX_LAST only (MultiIndex columns)\n",
    "px = px_all.xs(\"PX_LAST\", axis=1, level=\"metric\")\n",
    "# Resample to month end\n",
    "px_m = px.resample(\"M\").last()\n",
    "\n",
    "keep_metrics = [\n",
    "\n",
    "    # VALUE\n",
    "    \"PE_RATIO\",\n",
    "    \"PX_TO_BOOK_RATIO\",\n",
    "    \"PX_TO_SALES_RATIO\",\n",
    "    \"CURRENT_EV_TO_T12M_EBITDA\",\n",
    "    \"FREE_CASH_FLOW_YIELD\",\n",
    "    \"EQY_DVD_YLD_12M\",\n",
    "\n",
    "    # QUALITY\n",
    "    \"EBITDA_MARGIN\",\n",
    "    \"GROSS_MARGIN\",\n",
    "    \"OPER_MARGIN\",\n",
    "    \"PROF_MARGIN\",\n",
    "    \"RETURN_ON_ASSET\",\n",
    "\n",
    "    # LEVERAGE\n",
    "    \"TOT_DEBT_TO_EBITDA\",\n",
    "    \"TOT_DEBT_TO_TOT_EQY\",\n",
    "\n",
    "    # SIZE\n",
    "    \"CURRENT_MARKET_CAP_SHARE_CLASS\",\n",
    "\n",
    "    # RISK\n",
    "    \"BETA_ADJ_OVERRIDABLE\",\n",
    "    \"VOLATILITY_30D\", \"VOLATILITY_90D\", \"VOLATILITY_180D\", \"VOLATILITY_360D\",\n",
    "\n",
    "    # TAIL RISK\n",
    "    \"RET_SKEW_30D\", \"RET_SKEW_90D\", \"RET_SKEW_180D\", \"RET_SKEW_360D\",\n",
    "    \"RET_KURT_30D\", \"RET_KURT_180D\", \"RET_KURT_360D\", \"RET_KURT_90D\",\n",
    "\n",
    "    # LIQUIDITY\n",
    "    \"TURNOVER\",\"RET_30D\"\n",
    "]\n",
    "\n",
    "# 1. Clean data\n",
    "\n",
    "def _winsorize_row(row, lower,   upper):\n",
    "    if row.isna().all():\n",
    "        return row\n",
    "    lo, hi = row.quantile([lower, upper])\n",
    "    return row.clip(lo, hi)\n",
    "\n",
    "def clean_data(df, lower= 0.01, upper = 0.99):\n",
    "    \n",
    "    df_w = df.apply(_winsorize_row, axis=1, args=(lower, upper))\n",
    "    #zscore\n",
    "    mean_cs = df_w.mean(axis=1)\n",
    "    std_cs = df_w.std(axis=1).replace(0, np.nan)\n",
    "    df_z=df_w.sub(mean_cs, axis=0).div(std_cs, axis=0)\n",
    "    return df_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd3445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find trade dates\n",
    "def ewma(factors_kmeans,lambda_=0.94):\n",
    "    alpha = 1 - lambda_\n",
    "\n",
    "    metrics_in_data = factors_kmeans.columns.get_level_values(\"metric\").unique()\n",
    "\n",
    "    for m in metrics_in_data:\n",
    "        X = factors_kmeans.xs(m, axis=1, level=\"metric\")\n",
    "        X_smooth = X.ewm(alpha=alpha, adjust=False, min_periods=1).mean()\n",
    "\n",
    "        X_smooth.columns = pd.MultiIndex.from_product(\n",
    "            [[m], X_smooth.columns], names=[\"metric\", \"stock\"]\n",
    "        )\n",
    "\n",
    "        mask = factors_kmeans.columns.get_level_values(\"metric\") == m\n",
    "        factors_kmeans.loc[:, mask] = X_smooth.values\n",
    "    return factors_kmeans\n",
    "\n",
    "def get_trade_dates(px_m,factors_std,gap):\n",
    "    fwd_ret_m = np.log(px_m.shift(-1)) - np.log(px_m)\n",
    "    mom_6_1 = np.log(px_m.shift(1)) - np.log(px_m.shift(gap+1))\n",
    "    mom6_z = clean_data(mom_6_1.shift(gap))\n",
    "\n",
    "    factors_kmeans = factors_std.loc[:, factors_std.columns.get_level_values(\"metric\").isin(keep_metrics)]\n",
    "    factors_kmeans = factors_kmeans.ffill()\n",
    "    factors_kmeans_m=ewma(factors_kmeans)\n",
    "\n",
    "    rebalance_dates = mom6_z.dropna(how=\"all\").index\n",
    "    rebalance_dates = rebalance_dates.intersection(factors_kmeans_m.index)\n",
    "    rebalance_dates = rebalance_dates.intersection(fwd_ret_m.index)\n",
    "\n",
    "    rebalance_dates = rebalance_dates[(rebalance_dates >= \"2011-01-31\") &\n",
    "                                  (rebalance_dates <= \"2020-12-31\")]\n",
    "    return rebalance_dates,factors_kmeans_m,mom6_z,fwd_ret_m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cd87a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orig_weights(rebalance_dates,factors_kmeans_m,K):\n",
    "    #compute clusters\n",
    "    clusters_dict = {}\n",
    "    # go through all time\n",
    "    for t_idx, t in enumerate(rebalance_dates[:-1]):\n",
    "        row_t = factors_kmeans_m.loc[t]\n",
    "        X_t = row_t.unstack(\"metric\") \n",
    "        \n",
    "        min_valid = int(0.7 * X_t.shape[1])\n",
    "        X_t = X_t.dropna(axis=0, thresh=min_valid).fillna(0)\n",
    "        \n",
    "        km = KMeans(n_clusters=K, n_init=50, random_state=0)\n",
    "        labels = km.fit_predict(X_t.values)\n",
    "        clusters_t = pd.Series(labels, index=X_t.index, name=\"cluster  \")\n",
    "        clusters_dict[t] = clusters_t\n",
    "    return clusters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7682fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _obj(w,mu,cov):\n",
    "    ret = float(np.dot(w, mu))\n",
    "    var = float(w @ cov @ w)\n",
    "    if var <= 0:\n",
    "        return 1e6  \n",
    "    sharpe = ret / np.sqrt(var)\n",
    "    return -sharpe\n",
    "\n",
    "def _turnover_con(w, w0, tau):\n",
    "    return tau - np.sum(np.abs(w - w0))\n",
    "\n",
    "def _beta_neutral_con(w, beta):\n",
    "    #  w^T beta = 0\n",
    "    return float(np.dot(w, beta))\n",
    "\n",
    "\n",
    "def max_sharpe_opt(mu, cov, w0,beta, w_max=0.010, tau=0.05):\n",
    "    \"\"\"\n",
    "    max (w^T mu / sqrt(w^T Σ w))\n",
    "        1) sum w = 0\n",
    "        2) |w_i| <= w_max\n",
    "        3) ∑ |w_i - w0_i| <= tau\n",
    "        4) w^T beta = 0 \n",
    "    \"\"\"\n",
    "    n = len(mu)\n",
    "    if n == 0:\n",
    "        return np.array([])\n",
    "    \n",
    "\n",
    "    cons = [\n",
    "        {\"type\": \"eq\", \"fun\": lambda w: np.sum(w)},\n",
    "        {\"type\": \"eq\",  \"fun\": _beta_neutral_con, \"args\": (beta,)}, \n",
    "        {\"type\": \"ineq\",\"fun\": _turnover_con,\"args\": (w0, tau)}\n",
    "    ]\n",
    "    bounds = [(-w_max, w_max)] * n\n",
    "    w_init = np.clip(w0, -w_max, w_max)\n",
    "    \n",
    "    res = minimize(_obj,w_init,args=(mu, cov),\n",
    "                   method=\"SLSQP\",bounds=bounds,\n",
    "                   constraints=cons,\n",
    "                   options={\"maxiter\": 500, \"ftol\": 1e-9, \"disp\": False})\n",
    "    return res.x\n",
    "\n",
    "def get_optimal_weights(t,clusters_t,mom_t,beta_t,price_df,\n",
    "                        top_per=0.2,tail_per=0.2,lookback_months=6,\n",
    "                        w_max=0.07,tau=0.05):\n",
    "    w_all = pd.Series(0.0, index=clusters_t.index)\n",
    "    w_all_orig = pd.Series(0.0, index=clusters_t.index)\n",
    "    for cl in clusters_t.unique():\n",
    "        in_cl = clusters_t[clusters_t ==cl].index\n",
    "        mom_cl = mom_t.reindex(in_cl).dropna()\n",
    "        len_cl=len(in_cl)\n",
    "        top = mom_cl.nlargest(int(len_cl*top_per))\n",
    "        bottom = mom_cl.nsmallest(int(len_cl*tail_per))\n",
    "        selected = pd.Index(top.index.union(bottom.index))\n",
    "\n",
    "        w_long =  top / top.sum()     # sum = +1\n",
    "        w_short = bottom / abs(bottom.sum())  # sum = -1\n",
    "        w = pd.concat([w_long, w_short])\n",
    "\n",
    "        start = t - pd.DateOffset(months=lookback_months)\n",
    "        px_win = price_df.loc[start:t, selected].dropna(how=\"any\")\n",
    "\n",
    "        ret_win = np.log(px_win).diff().dropna() # type: ignore\n",
    "        cov = ret_win.cov()\n",
    "        mu = mom_cl.reindex(selected).values\n",
    "        w_opt = max_sharpe_opt(mu=mu,cov=cov,w0=w,beta=beta_t,w_max=w_max,tau=tau)\n",
    "\n",
    "        w_opt_s = pd.Series(w_opt, index=selected)*int(len_cl )/len(clusters_t)\n",
    "        w_orig=pd.Series(w, index=selected)*int(len_cl )/len(clusters_t)\n",
    "        w_all.loc[selected] = w_opt_s\n",
    "        w_all_orig.loc[selected] = w_orig\n",
    "\n",
    "    return w_all,w_all_orig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85e950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _one_date_weights(t, clusters, mom6_z, px,beta):\n",
    "\n",
    "    clusters_t = clusters.loc[t]     \n",
    "    mom_t      = mom6_z.loc[t] \n",
    "    beta_t=beta.loc[t]  \n",
    "    price_df   = px                  \n",
    "\n",
    "    w_opt,w_opt_orig = get_optimal_weights(t, clusters_t, mom_t, price_df,beta_t)\n",
    "    w_opt.name = t \n",
    "    w_opt_orig.name = t\n",
    "    return w_opt,w_opt_orig\n",
    "\n",
    "\n",
    "def run_parallel_weights(rebalance_dates, clusters, mom6_z, px, beta, n_jobs=-1):\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(_one_date_weights)(t, clusters, mom6_z, px,beta)\n",
    "        for t in rebalance_dates\n",
    "    )\n",
    "\n",
    "    # results: list of (w_opt, w_opt_orig)\n",
    "    w_opt_list, w_opt_orig_list = zip(*results)\n",
    "\n",
    "    weights_df = pd.DataFrame(w_opt_list)\n",
    "    weights_df.index.name = \"date\"\n",
    "\n",
    "    weights_orig_df = pd.DataFrame(w_opt_orig_list)\n",
    "    weights_orig_df.index.name = \"date\"\n",
    "\n",
    "    return weights_df, weights_orig_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098243c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m beta_path\u001b[38;5;241m=\u001b[39m\u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_beta.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m beta\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(beta_path,index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "beta_path=os.path.join(data_path,'df_beta.csv')\n",
    "beta=pd.read_csv(beta_path,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee289344",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=30\n",
    "gap=2\n",
    "\n",
    "rebalance_dates,factors_kmeans_m,mom6_z,fwd_ret_m=get_trade_dates(px_m,factors_std,gap)\n",
    "clusters_dict=get_orig_weights(rebalance_dates,factors_kmeans_m,k)\n",
    "clusters= pd.DataFrame(clusters_dict).T\n",
    "\n",
    "weights_df, weights_orig_df = run_parallel_weights(rebalance_dates[:-1], clusters, mom6_z, px,beta, n_jobs=8)\n",
    "\n",
    "weights_df.to_csv(f'weights_{k}_{gap}.csv')\n",
    "weights_orig_df.to_csv(f'weights_orig_{k}_{gap}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hwenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
